{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need:\n",
    "\n",
    "* PyTorch\n",
    "* Torchvision\n",
    "* Scikit-Learn\n",
    "* OpenCV\n",
    "* Clone https://github.com/y0ast/Glow-PyTorch/tree/181daaffcd0f3561f08c32d5b3846874bcc0481a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your folder where you cloned the glow-repo linked above\n",
    "glow_code_folder = os.path.join(os.environ['HOME'], 'code/glow-do-deep/glow_do_deep/')\n",
    "\n",
    "# Set your folder where you downloaded pretrained glow model from \n",
    "# https://github.com/y0ast/Glow-PyTorch\n",
    "# http://www.cs.ox.ac.uk/people/joost.vanamersfoort/glow.zip\n",
    "output_folder = os.path.join(os.environ['HOME'], 'code/glow-do-deep/glow/')\n",
    "\n",
    "\n",
    "# Set here path to your PyTorch-CIFAR10/SVHN datasets\n",
    "cifar10_path =  os.path.join(os.environ['HOME'], 'data/pytorch-datasets/data/CIFAR10/')\n",
    "svhn_path =  os.path.join(os.environ['HOME'], 'data/pytorch-datasets/data/SVHN/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..anonymized/ipykernel_launcher.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import json\n",
    "\n",
    "# Load tqdm if available for progress bar\n",
    "# otherwise just no progress bar\n",
    "try:\n",
    "    from tqdm.autonotebook import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    def tqdm(x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 32, 'L': 3, 'LU_decomposed': True, 'actnorm_scale': 1.0, 'augment': True, 'batch_size': 64, 'cuda': True, 'dataroot': './', 'dataset': 'cifar10', 'download': False, 'epochs': 1500, 'eval_batch_size': 512, 'flow_coupling': 'affine', 'flow_permutation': 'invconv', 'fresh': True, 'hidden_channels': 512, 'learn_top': True, 'lr': 0.0005, 'max_grad_clip': 0, 'max_grad_norm': 0, 'n_init_batches': 8, 'n_workers': 6, 'output_dir': 'output/', 'saved_model': '', 'saved_optimizer': '', 'seed': 0, 'warmup_steps': 4000, 'y_condition': False, 'y_weight': 0.01}\n"
     ]
    }
   ],
   "source": [
    "os.chdir(glow_code_folder)\n",
    "from model import Glow\n",
    "model_name = 'glow_affine_coupling.pt'\n",
    "\n",
    "with open(output_folder + 'hparams.json') as json_file:  \n",
    "    hparams = json.load(json_file)\n",
    "    \n",
    "print(hparams)\n",
    "image_shape = (32,32,3)\n",
    "num_classes = 10\n",
    "model = Glow(image_shape, hparams['hidden_channels'], hparams['K'], hparams['L'], hparams['actnorm_scale'],\n",
    "             hparams['flow_permutation'], hparams['flow_coupling'], hparams['LU_decomposed'], num_classes,\n",
    "             hparams['learn_top'], hparams['y_condition'])\n",
    "\n",
    "model.load_state_dict(torch.load(output_folder + model_name))\n",
    "model.set_actnorm_init()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "\n",
    "Set `download=True` in case you don't have them yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_svhn = datasets.SVHN(\n",
    "    svhn_path,\n",
    "    split='test',\n",
    "    download=False)\n",
    "\n",
    "\n",
    "test_cifar10 = datasets.CIFAR10(\n",
    "    cifar10_path,\n",
    "    train=False,\n",
    "    download=False)\n",
    "\n",
    "pytorch_datasets = dict(test_cifar10=test_cifar10,\n",
    "               test_svhn=test_svhn)\n",
    "\n",
    "np_arrays = dict()\n",
    "loaders = dict()\n",
    "for name, dataset in pytorch_datasets.items():\n",
    "    np_arr = np.stack([np.array(x) for x,y in dataset])\n",
    "    np_arrays[name] = np_arr\n",
    "    # Ensure we are working on exactly same data.\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.Tensor(np_arr)),\n",
    "            batch_size=512, drop_last=False)\n",
    "    loaders[name] = loader\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PNG BPDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782ba2dc77244423b208b996a8830e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6071a32f4184443b90ae9c8ee110c81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26032), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def create_png_bpds(np_im_arr,):\n",
    "    all_bpds = []\n",
    "    for i_file, a_x in enumerate(tqdm(np_im_arr)):\n",
    "        # This code was written using an author reply to our mails\n",
    "        # Use highest compression level (9)\n",
    "        img_encoded = cv2.imencode('.png', a_x, [int(cv2.IMWRITE_PNG_COMPRESSION),9])[1]\n",
    "        assert img_encoded.shape[1] == 1\n",
    "        all_bpds.append((len(img_encoded) * 8)/np.prod(a_x.shape))\n",
    "    return all_bpds\n",
    "\n",
    "\n",
    "png_bpds = dict([\n",
    "    (name, create_png_bpds(np_im_arr))\n",
    "    for name, np_im_arr in np_arrays.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute BPDs of Glow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, ):\n",
    "    # Preprocess from tensor with:\n",
    "    # dim ordering: B,H,W,C\n",
    "    # values: 0-255 \n",
    "    # \n",
    "    # to tensor with\n",
    "    # dim ordering: B,C,H,W\n",
    "    # values: -0.5 to +0.5\n",
    "    # Follows:\n",
    "    # https://github.com/tensorflow/tensor2tensor/blob/e48cf23c505565fd63378286d9722a1632f4bef7/tensor2tensor/models/research/glow.py#L78\n",
    "    x = x.permute(0,3,1,2)\n",
    "    n_bits = 8\n",
    "    n_bins = 2**n_bits\n",
    "    x = x / n_bins - 0.5\n",
    "    return x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glow_bpds(model, loader):\n",
    "    all_bpds = []\n",
    "    for x, in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            preproced_x = preprocess(x)\n",
    "            _, bpd, _ =  model(preproced_x)\n",
    "        all_bpds.append(bpd.cpu().numpy())\n",
    "\n",
    "    all_bpds = np.concatenate(all_bpds)\n",
    "    return all_bpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001047b95bd6487896f89d8f9ed858c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa513b78876b422aa834e3395b095576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "glow_bpds = dict([\n",
    "    (name, compute_glow_bpds(model, loader))\n",
    "    for name, loader in loaders.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def compute_auc_for_s_scores(scores_ood, scores_itd):\n",
    "    # Assumes scores a should be higher\n",
    "    auc = roc_auc_score(\n",
    "        np.concatenate((np.ones_like(scores_ood),\n",
    "                       np.zeros_like(scores_itd)),\n",
    "                      axis=0),\n",
    "        np.concatenate((scores_ood,\n",
    "                       scores_itd,),\n",
    "                      axis=0))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reach substantially different values for S-Score (78.4% vs 95.0%), see https://arxiv.org/pdf/1909.11480.pdf Supplementary D, p.14, Table 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7837171385218193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_score_cifar10 = glow_bpds['test_cifar10'] - png_bpds['test_cifar10']\n",
    "s_score_svhn = glow_bpds['test_svhn'] - png_bpds['test_svhn']\n",
    "\n",
    "compute_auc_for_s_scores(s_score_svhn, s_score_cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reach similar numbers for PNG only (7.7% in paper vs 7.9% here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07867029233251382"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We reach si\n",
    "compute_auc_for_s_scores(png_bpds['test_svhn'], png_bpds['test_cifar10'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
